{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9739caa",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from json import dumps, loads\n",
    "from pathlib import Path\n",
    "from re import DOTALL, finditer, search\n",
    "from shlex import join, split\n",
    "from subprocess import run\n",
    "from typing import Annotated as Ann\n",
    "from typing import Literal, TypeAlias, TypedDict, overload\n",
    "\n",
    "from devtools import pprint\n",
    "from dotenv import load_dotenv\n",
    "from gjob_dev.notebooks import disp_named\n",
    "from gjob_pipeline.stages.convert import Convert as Params\n",
    "from more_itertools import first\n",
    "from pandas import DataFrame\n",
    "from pydantic import BaseModel, Field\n",
    "from seaborn import catplot\n",
    "\n",
    "\n",
    "def just(*args: str):\n",
    "    return run(\n",
    "        args=[\n",
    "            *split(\"pwsh -NonInteractive -NoProfile -CommandWithArgs\"),\n",
    "            f\"./j.ps1 --color never {join(args)}\",\n",
    "        ],\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "\n",
    "def prettier(*args: str):\n",
    "    return just(*split(f\"run prettier --no-color --write {join(args)}\"))\n",
    "\n",
    "\n",
    "load_dotenv(Path(just(\"sync-contrib-env-file\").stdout.strip()))\n",
    "PARAMS = None\n",
    "\"\"\"Notebook stage parameters.\"\"\"\n",
    "Params.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.model_validate_json(PARAMS) if isinstance(PARAMS, str) else Params()  # pyright: ignore[reportUnnecessaryIsInstance]\n",
    "mbox = params.deps.mboxes / params.mbox_name\n",
    "path = params.outs.reqs / f\"{mbox.stem}.json\"\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    just(\n",
    "        *split(f\"proj::convert-mbox-to-json {mbox.as_posix()} {path.as_posix()}\")\n",
    "    ).stdout.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    sender: Ann[str, Field(alias=\"from\")]\n",
    "    recipient: Ann[str, Field(alias=\"to\")]\n",
    "    subject: str\n",
    "    received: Ann[datetime, Field(alias=\"date\")]\n",
    "    body: str\n",
    "\n",
    "\n",
    "messages = [\n",
    "    Message(**message)\n",
    "    for message in loads(path.read_text(encoding=\"utf-8\"))\n",
    "    if message[\"from\"] == \"Job Alerts from Google <notify-noreply@google.com>\"\n",
    "]\n",
    "\n",
    "disp_named(\n",
    "    (\"Messages\", [message.model_dump() for message in messages]),\n",
    "    (\n",
    "        \"First message body\",\n",
    "        f\"{messages[0].body}...\" if len(messages[0].body) > 100 else messages[0].body,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alert(BaseModel):\n",
    "    query: str\n",
    "    search_location: str\n",
    "    received: datetime\n",
    "    jobs: list[str]\n",
    "    footer: str\n",
    "\n",
    "\n",
    "def get_newline(text: str) -> str:\n",
    "    return \"\\r\\n\" if \"\\r\\n\" in text else \"\\n\"\n",
    "\n",
    "\n",
    "def get_alert(message: Message) -> Alert:\n",
    "    newline = get_newline(message.body)\n",
    "    if match := search(\n",
    "        \"\".join([\n",
    "            r\"^\",\n",
    "            rf'\"(?P<query>.+?)\" in .+?{newline}',\n",
    "            rf\"(?P<search_location>.+?){newline}\",\n",
    "            rf\"(?P<jobs>.+){newline * 5}\",\n",
    "            rf\"(?P<footer>{''.join(['.+?', *(newline * 5)] * 3)})\",\n",
    "            r\"$\",\n",
    "        ]),\n",
    "        message.body,\n",
    "        flags=DOTALL,\n",
    "    ):\n",
    "        return Alert(\n",
    "            query=match[\"query\"].strip(),\n",
    "            search_location=match[\"search_location\"].strip(),\n",
    "            received=message.received,\n",
    "            jobs=[\n",
    "                m[\"job\"].strip()\n",
    "                for m in finditer(\n",
    "                    rf\"(?P<job>.+?){newline * 5}\", match[\"jobs\"].strip(), flags=DOTALL\n",
    "                )\n",
    "            ],\n",
    "            footer=\"\".join(match[\"footer\"]).strip(),\n",
    "        )\n",
    "    raise ValueError(\"Could not parse alert\")\n",
    "\n",
    "\n",
    "alerts = [get_alert(message) for message in messages]\n",
    "disp_named(\n",
    "    (\"Alerts\", [{**alert.model_dump()} for alert in alerts]),\n",
    "    (\n",
    "        f'Jobs for first alert for \"{alerts[0].query}\" in {alerts[0].search_location}',\n",
    "        alerts[0].model_dump(include={\"jobs\"}),\n",
    "    ),\n",
    "    (\n",
    "        f'First job for first alert for \"{alerts[0].query}\" in {alerts[0].search_location}',\n",
    "        first(alerts[0].jobs),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f63368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(BaseModel):\n",
    "    company: str\n",
    "    location: str\n",
    "    title: str\n",
    "    posted: date\n",
    "    source: str\n",
    "    full_time: bool\n",
    "    logo: str\n",
    "\n",
    "\n",
    "def get_job(text: str) -> Job:\n",
    "    newline = get_newline(text)\n",
    "    sp = \" \"\n",
    "    match = search(\n",
    "        \"\".join([\n",
    "            r\"^\",\n",
    "            rf\"(?P<logo>.+?){newline * 3}\",\n",
    "            rf\"(?P<title>.+?){newline * 1}\",\n",
    "            rf\"(?P<company>.+?){newline * 2}\",\n",
    "            rf\"(?P<location>.+?){newline * 2}\",\n",
    "            rf\"(?P<source>.+?){newline * 2}\",\n",
    "            r\"Time icon (?P<posted>.+?)\",\n",
    "            r\"(?P<full_time_specified>\\sWork icon (?P<full_time>.+?))?\",\n",
    "            r\"$\",\n",
    "        ]),\n",
    "        text,\n",
    "        flags=DOTALL,\n",
    "    )\n",
    "    if not match:\n",
    "        raise ValueError(\"Could not parse job\")\n",
    "    sp = \" \"\n",
    "    return Job(\n",
    "        title=match[\"title\"],\n",
    "        company=match[\"company\"],\n",
    "        location=match[\"location\"],\n",
    "        source=match[\"source\"].removeprefix(\"via\").strip(),\n",
    "        posted=datetime.strptime(\n",
    "            sp.join([match[\"posted\"], str(datetime.now().year).zfill(4)]), \"%b %d %Y\"\n",
    "        ).date(),\n",
    "        full_time=(\n",
    "            match[\"full_time\"].casefold() == \"full-time\"\n",
    "            if match[\"full_time_specified\"]\n",
    "            else True\n",
    "        ),\n",
    "        logo=match[\"logo\"],\n",
    "    )\n",
    "\n",
    "\n",
    "Jobs: TypeAlias = dict[str, dict[str, list[Job]]]\n",
    "\n",
    "jobs: Jobs = {}\n",
    "for alert in alerts:\n",
    "    jobs_for_query = jobs.get(alert.query)\n",
    "    if not jobs_for_query:\n",
    "        jobs[alert.query] = {}\n",
    "    jobs_for_search_location = jobs[alert.query].get(alert.search_location)\n",
    "    if not jobs_for_search_location:\n",
    "        jobs[alert.query][alert.search_location] = []\n",
    "    jobs[alert.query][alert.search_location].extend([\n",
    "        get_job(job) for job in alert.jobs\n",
    "    ])\n",
    "\n",
    "\n",
    "class DictJob(TypedDict):\n",
    "    title: str\n",
    "    company: str\n",
    "    location: str\n",
    "    source: str\n",
    "    posted: date\n",
    "    full_time: bool\n",
    "    logo: str\n",
    "\n",
    "\n",
    "DumpedJobs: TypeAlias = dict[str, dict[str, list[DictJob]]]\n",
    "SerializedJobs: TypeAlias = dict[str, dict[str, list[dict[str, str]]]]\n",
    "\n",
    "\n",
    "@overload\n",
    "def dump_jobs(jobs: Jobs) -> DumpedJobs: ...\n",
    "@overload\n",
    "def dump_jobs(jobs: Jobs, mode: Literal[\"python\"]) -> DumpedJobs: ...\n",
    "@overload\n",
    "def dump_jobs(jobs: Jobs, mode: Literal[\"json\"]) -> SerializedJobs: ...\n",
    "def dump_jobs(\n",
    "    jobs: Jobs, mode: Literal[\"python\", \"json\"] = \"python\"\n",
    ") -> DumpedJobs | SerializedJobs:\n",
    "    return {\n",
    "        query: {\n",
    "            search_location: [job.model_dump(mode=mode) for job in jobs]\n",
    "            for search_location, jobs in jobs_for_query.items()\n",
    "        }\n",
    "        for query, jobs_for_query in jobs.items()\n",
    "    }\n",
    "\n",
    "\n",
    "reqs_path = params.outs.reqs / f\"{mbox.stem}-reqs.json\"\n",
    "reqs_path.write_text(encoding=\"utf-8\", data=dumps(dump_jobs(jobs, mode=\"json\")))\n",
    "\n",
    "disp_named(\n",
    "    (\"Jobs\", dump_jobs(jobs, mode=\"json\")),\n",
    "    (\n",
    "        f'First job for query \"{first(jobs)}\" in search location \"{first(first(jobs.values()))}\"',\n",
    "        first(first(first(jobs.values()).values())).model_dump(),\n",
    "    ),\n",
    "    (\"Prettier\", prettier(reqs_path.as_posix()).stdout),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \" \"\n",
    "nyny = \"New York, NY, United States\"\n",
    "newlines = [\"\\r\\n\", \"\\n\"]\n",
    "columns = {\n",
    "    **dict.fromkeys(\n",
    "        [\n",
    "            \"query\",\n",
    "            \"country\",\n",
    "            \"state_or_province\",\n",
    "            \"city\",\n",
    "            \"company\",\n",
    "            \"title\",\n",
    "            \"full_time\",\n",
    "            \"posted\",\n",
    "            \"source\",\n",
    "            \"location\",\n",
    "        ],\n",
    "        True,\n",
    "    ),\n",
    "    \"posted\": False,\n",
    "}\n",
    "drop = [\"location\"]\n",
    "df = (\n",
    "    DataFrame(\n",
    "        data=(\n",
    "            {\"query\": query, \"country\": search_location, **job}\n",
    "            for query, jobs_for_query in dump_jobs(jobs).items()\n",
    "            for search_location, jobs_for_search_location in jobs_for_query.items()\n",
    "            for job in jobs_for_search_location\n",
    "        ),\n",
    "        columns=list(columns.keys()),\n",
    "    )\n",
    "    .replace(\n",
    "        to_replace={\n",
    "            \"location\": {\n",
    "                **dict.fromkeys(\n",
    "                    [\n",
    "                        f\"The DE Shaw Group, Two Manhattan West, 375 9th Ave 52nd Floor, New York,  {newline}NY, United States\"\n",
    "                        for newline in newlines\n",
    "                    ],\n",
    "                    nyny,\n",
    "                ),\n",
    "                **dict.fromkeys(\n",
    "                    [\n",
    "                        f\"IBM Thomas J. Watson Research Center, 1101 Kitchawan Rd, Yorktown Heights,  {newline}NY, United States\"\n",
    "                        for newline in newlines\n",
    "                    ],\n",
    "                    nyny,\n",
    "                ),\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .assign(**{\n",
    "        \"state_or_province\": lambda df: df[\"location\"]\n",
    "        .where(df[\"location\"].str.count(\",\") > 0)\n",
    "        .str.split(f\",{sp}\")\n",
    "        .str[-2],\n",
    "        \"city\": lambda df: df[\"location\"]\n",
    "        .where(df[\"location\"].str.count(\",\") > 1)\n",
    "        .str.split(f\",{sp}\")\n",
    "        .str[0],\n",
    "    })\n",
    "    .sort_values(ascending=list(columns.values()), by=list(columns.keys()))\n",
    "    .replace(to_replace={\"state_or_province\": {\"Quebec\": \"QB\"}})\n",
    ")\n",
    "df.drop(axis=\"columns\", labels=drop).to_csv(params.outs.reqs / f\"{mbox.stem}-reqs.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"state_or_province == 'WA' & query == 'Research software engineer'\"\n",
    "aspect = 1.0\n",
    "threshold = 0.00\n",
    "g = catplot(\n",
    "    aspect=aspect,\n",
    "    errorbar=None,\n",
    "    hue=\"city\",\n",
    "    kind=\"bar\",\n",
    "    x=\"city\",\n",
    "    y=\"count\",\n",
    "    data=(\n",
    "        df.query(query)\n",
    "        .assign(**{\n",
    "            \"city\": df[\"city\"],\n",
    "            \"count\": df[\"city\"].map(df[\"city\"].value_counts()),\n",
    "        })\n",
    "        .pipe(lambda df: df[df[\"count\"] > threshold * df[\"count\"].max()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    ),\n",
    ")\n",
    "query = \"query == 'Research software engineer'\"\n",
    "aspect = 5.0\n",
    "threshold = 0.07\n",
    "catplot(\n",
    "    errorbar=None,\n",
    "    hue=\"state_or_province\",\n",
    "    kind=\"bar\",\n",
    "    x=\"state_or_province\",\n",
    "    y=\"count\",\n",
    "    data=(\n",
    "        df.query(query)\n",
    "        .assign(**{\n",
    "            \"city\": df[\"state_or_province\"],\n",
    "            \"count\": df[\"state_or_province\"].map(\n",
    "                df[\"state_or_province\"].value_counts()\n",
    "            ),\n",
    "        })\n",
    "        .pipe(lambda df: df[df[\"count\"] > threshold * df[\"count\"].max()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    ),\n",
    ")\n",
    "threshold = 0.05\n",
    "catplot(\n",
    "    aspect=aspect,\n",
    "    errorbar=None,\n",
    "    hue=\"city\",\n",
    "    kind=\"bar\",\n",
    "    x=\"city\",\n",
    "    y=\"count\",\n",
    "    data=(\n",
    "        df.query(query)\n",
    "        .assign(**{\n",
    "            \"city\": df[\"city\"],\n",
    "            \"count\": df[\"city\"].map(df[\"city\"].value_counts()),\n",
    "        })\n",
    "        .pipe(lambda df: df[df[\"count\"] > threshold * df[\"count\"].max()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    ),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d769b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"query == 'Thermal'\"\n",
    "aspect = 6.0\n",
    "threshold = 0.07\n",
    "catplot(\n",
    "    errorbar=None,\n",
    "    hue=\"state_or_province\",\n",
    "    kind=\"bar\",\n",
    "    x=\"state_or_province\",\n",
    "    y=\"count\",\n",
    "    data=(\n",
    "        df.query(query)\n",
    "        .assign(**{\n",
    "            \"city\": df[\"state_or_province\"],\n",
    "            \"count\": df[\"state_or_province\"].map(\n",
    "                df[\"state_or_province\"].value_counts()\n",
    "            ),\n",
    "        })\n",
    "        .pipe(lambda df: df[df[\"count\"] > threshold * df[\"count\"].max()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    ),\n",
    ")\n",
    "threshold = 0.05\n",
    "catplot(\n",
    "    aspect=aspect,\n",
    "    errorbar=None,\n",
    "    hue=\"city\",\n",
    "    kind=\"bar\",\n",
    "    x=\"city\",\n",
    "    y=\"count\",\n",
    "    data=(\n",
    "        df.query(query)\n",
    "        .assign(**{\n",
    "            \"city\": df[\"city\"],\n",
    "            \"count\": df[\"city\"].map(df[\"city\"].value_counts()),\n",
    "        })\n",
    "        .pipe(lambda df: df[df[\"count\"] > threshold * df[\"count\"].max()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    ),\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gjob (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
